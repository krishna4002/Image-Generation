{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Install dependencies\n",
        "!pip install -q streamlit diffusers transformers torch accelerate scipy safetensors pyngrok pillow\n",
        "!pip install huggingface_hub -q"
      ],
      "metadata": {
        "id": "jLoKDoP8Fsi2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "ngrok.set_auth_token(\"2xfLLqgERPi1VkxbtVUPWjdzJwD_RvfDPsLKMtozVgoCiyNA\")"
      ],
      "metadata": {
        "id": "6YK5CF-gGEWk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3️⃣ Save Streamlit app code as app.py\n",
        "%%writefile app.py\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import streamlit as st\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionInpaintPipeline, StableDiffusionImg2ImgPipeline\n",
        "\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_text2img_model():\n",
        "    return StableDiffusionPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_img2img_model():\n",
        "    return StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "@st.cache_resource(show_spinner=False)\n",
        "def load_inpaint_model():\n",
        "    return StableDiffusionInpaintPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-2-inpainting\",\n",
        "        revision=\"fp16\" if torch.cuda.is_available() else \"main\",\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pipe_txt2img = load_text2img_model()\n",
        "pipe_img2img = load_img2img_model()\n",
        "pipe_inpaint = load_inpaint_model()\n",
        "\n",
        "st.set_page_config(page_title=\"Image Generation App\", layout=\"centered\")\n",
        "\n",
        "st.title(\"Image Generation - Text2Image, Variation & Inpainting\")\n",
        "\n",
        "mode = st.radio(\"Select Operation\", [\"Text-to-Image\", \"Image Variation\", \"Inpainting\"])\n",
        "\n",
        "if mode == \"Text-to-Image\":\n",
        "    prompt = st.text_area(\"Enter your prompt\", height=150)\n",
        "    steps = st.slider(\"Inference Steps\", 10, 50, 30)\n",
        "    guidance_scale = st.slider(\"Guidance Scale\", 5.0, 15.0, 7.5)\n",
        "    if st.button(\"Generate Image\"):\n",
        "        if not prompt.strip():\n",
        "            st.warning(\"Please enter a prompt.\")\n",
        "        else:\n",
        "            with st.spinner(\"Generating image...\"):\n",
        "                image = pipe_txt2img(prompt=prompt, guidance_scale=guidance_scale, num_inference_steps=steps).images[0]\n",
        "            st.image(image, caption=prompt)\n",
        "            buffered = BytesIO()\n",
        "            image.save(buffered, format=\"PNG\")\n",
        "            st.download_button(\"Download Image\", data=buffered.getvalue(), file_name=\"text2img.png\", mime=\"image/png\")\n",
        "\n",
        "elif mode == \"Image Variation\":\n",
        "    uploaded_file = st.file_uploader(\"Upload an image (PNG/JPEG)\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "    prompt = st.text_area(\"Optional prompt for variation\", height=100)\n",
        "    steps = st.slider(\"Inference Steps\", 10, 50, 30)\n",
        "    guidance_scale = st.slider(\"Guidance Scale\", 5.0, 15.0, 7.5)\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        init_image = Image.open(uploaded_file).convert(\"RGB\")\n",
        "        st.image(init_image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "        if st.button(\"Generate Variation\"):\n",
        "            with st.spinner(\"Generating image variation...\"):\n",
        "                init_image = init_image.resize((512, 512))\n",
        "                image = pipe_img2img(prompt=prompt if prompt.strip() else None,\n",
        "                                     image=init_image,\n",
        "                                     strength=0.75,\n",
        "                                     guidance_scale=guidance_scale,\n",
        "                                     num_inference_steps=steps).images[0]\n",
        "            st.image(image, caption=\"Image Variation\")\n",
        "            buffered = BytesIO()\n",
        "            image.save(buffered, format=\"PNG\")\n",
        "            st.download_button(\"Download Image\", data=buffered.getvalue(), file_name=\"variation.png\", mime=\"image/png\")\n",
        "\n",
        "elif mode == \"Inpainting\":\n",
        "    uploaded_file = st.file_uploader(\"Upload original image (PNG/JPEG)\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "    mask_file = st.file_uploader(\"Upload mask image (white=area to modify)\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "    prompt = st.text_area(\"Inpainting prompt (e.g., 'Add a spaceship')\", height=100)\n",
        "    steps = st.slider(\"Inference Steps\", 10, 50, 30)\n",
        "    guidance_scale = st.slider(\"Guidance Scale\", 5.0, 15.0, 7.5)\n",
        "\n",
        "    if uploaded_file is not None and mask_file is not None:\n",
        "        original = Image.open(uploaded_file).convert(\"RGB\").resize((512, 512))\n",
        "        mask = Image.open(mask_file).convert(\"RGB\").resize((512, 512))\n",
        "        st.image(original, caption=\"Original Image\", use_column_width=True)\n",
        "        st.image(mask, caption=\"Mask Image\", use_column_width=True)\n",
        "\n",
        "        if st.button(\"Generate Inpainting\"):\n",
        "            if not prompt.strip():\n",
        "                st.warning(\"Please enter an inpainting prompt.\")\n",
        "            else:\n",
        "                with st.spinner(\"Generating inpainting...\"):\n",
        "                    image = pipe_inpaint(prompt=prompt,\n",
        "                                         image=original,\n",
        "                                         mask_image=mask,\n",
        "                                         guidance_scale=guidance_scale,\n",
        "                                         num_inference_steps=steps).images[0]\n",
        "                st.image(image, caption=\"Inpainting Result\")\n",
        "                buffered = BytesIO()\n",
        "                image.save(buffered, format=\"PNG\")\n",
        "                st.download_button(\"Download Image\", data=buffered.getvalue(), file_name=\"inpaint.png\", mime=\"image/png\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc0p3bDpGpqs",
        "outputId": "f9ab6893-bd52-44f2-f289-9cceb2f5834d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set ngrok authtoken\n",
        "ngrok.set_auth_token(\"2xfLLqgERPi1VkxbtVUPWjdzJwD_RvfDPsLKMtozVgoCiyNA\")\n",
        "\n",
        "# Start Streamlit in a thread\n",
        "def run_streamlit():\n",
        "    subprocess.call([\"streamlit\", \"run\", \"app.py\"])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.start()\n",
        "\n",
        "# Wait for Streamlit to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Connect to port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit app is live at:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBfsK6ezSb2I",
        "outputId": "8bbb2997-27f5-46c6-8f3a-73ca4967d711"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://9566-34-127-114-65.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZ05Kcp8YYUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}